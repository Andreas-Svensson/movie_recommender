{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of Logical Error\n",
    "\n",
    "There was a logical error in the code-along code, this is my process for identifying and solving it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from fuzzywuzzy import process\n",
    "from IPython.display import display"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code-Along Code (With Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv(\"assets/movies_small.csv\", usecols = [\"movieId\", \"title\"])\n",
    "df_ratings = pd.read_csv(\"assets/ratings_small.csv\", usecols = [\"userId\", \"movieId\", \"rating\"])\n",
    "\n",
    "movies_cat = pd.Categorical(df_ratings['movieId'])\n",
    "users_cat = pd.Categorical(df_ratings['userId'])\n",
    "\n",
    "mat_movies_users = csr_matrix((df_ratings['rating'], (movies_cat.codes, users_cat.codes)))\n",
    "\n",
    "model_KNN = NearestNeighbors(metric = \"cosine\", algorithm = \"brute\")\n",
    "model_KNN.fit(mat_movies_users) # fitting model to sparse matrix\n",
    "\n",
    "def recommender(movie_name, model = model_KNN, data = mat_movies_users, n_recommendations = 9):\n",
    "    idx = process.extractOne(movie_name, df_movies[\"title\"])[2]\n",
    "\n",
    "    distances, indices = model.kneighbors(data[idx], n_neighbors = n_recommendations + 1)\n",
    "\n",
    "    indices = indices.flatten()[1:]\n",
    "    \n",
    "    # print results:\n",
    "    print(f\"Movie Selected: \\\"{df_movies.loc[idx]['title']}\\\"\\n\") # selected movie title\n",
    "    for a, i in enumerate(indices): # looping through indices:\n",
    "        print(f\"{a + 1}. {df_movies.loc[i]['title']}\") # print each title in order from closest to farthest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the small dataset, the recommendations are really bad\n",
    "\n",
    "Initially thought it was due to size of dataset, but it is possible to find similar results in the full dataset as well when searching for less popular movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Selected: \"Star Wars: Episode IV - A New Hope (1977)\"\n",
      "\n",
      "1. Cheech and Chong's Up in Smoke (1978)\n",
      "2. Once Upon a Time in the West (C'era una volta il West) (1968)\n",
      "3. Princess Bride, The (1987)\n",
      "4. Walk on the Moon, A (1999)\n",
      "5. Some Kind of Wonderful (1987)\n",
      "6. Arsenic and Old Lace (1944)\n",
      "7. Black Mask (Hak hap) (1996)\n",
      "8. Local Hero (1983)\n",
      "9. Godfather, The (1972)\n"
     ]
    }
   ],
   "source": [
    "recommender(\"Star Wars\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since movies are sorted from more to less popular, if less popular movies don't give good recommendations it makes sense for there to be an index mismatch somewhere in the dataset  \n",
    "\n",
    "This would also explain why the small dataset gives worse recommendations, as removing more movies would create index mismatches earlier in the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Created test function to check for index mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(indices):\n",
    "    errors = 0\n",
    "    \n",
    "    for idx in indices:\n",
    "        id = df_movies.loc[idx][\"movieId\"]\n",
    "        sum_dataframe = df_ratings[df_ratings[\"movieId\"] == id][\"rating\"].sum()\n",
    "        sum_matrix = mat_movies_users[idx].sum()\n",
    "\n",
    "\n",
    "        if sum_dataframe != sum_matrix:\n",
    "            errors += 1\n",
    "            print(f\"Comparing index {idx}, result: {sum_dataframe == sum_matrix} ({sum_dataframe, sum_matrix})\")\n",
    "        \n",
    "    if errors == 0:\n",
    "        print(\"All indices tested with no mismatches\")\n",
    "    print(f\"{errors} errors found\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initially, indices seem to line up properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All indices tested with no mismatches\n",
      "0 errors found\n"
     ]
    }
   ],
   "source": [
    "indices = [i for i in range(0, 500)]\n",
    "test(indices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### However, at index 816 something happens\n",
    "\n",
    "From index 816, every single index is mismatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing index 816, result: False ((0.0, 105.0))\n",
      "Comparing index 817, result: False ((105.0, 37.5))\n",
      "Comparing index 818, result: False ((37.5, 278.5))\n",
      "Comparing index 819, result: False ((278.5, 349.5))\n",
      "4 errors found\n"
     ]
    }
   ],
   "source": [
    "indices = [i for i in range(800, 820)]\n",
    "test(indices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the full dataset, this is seen at index 8403 and up\n",
    "\n",
    "This explains why rarely some movies give very bad recommendations even in the large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing index 8403, result: False ((0.0, 201.0))\n",
      "Comparing index 8404, result: False ((201.0, 97.0))\n",
      "Comparing index 8405, result: False ((97.0, 131.0))\n",
      "Comparing index 8406, result: False ((131.0, 104.5))\n",
      "4 errors found\n"
     ]
    }
   ],
   "source": [
    "# indices = [i for i in range(8400, 8407)]\n",
    "# test(indices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the issue\n",
    "\n",
    "An issue with index mismatching has been seen in both datasets, but more commonly in the small dataset  \n",
    "\n",
    "\n",
    "Describing the recommender:  \n",
    "1. In the recommender function, an index matching the input title is picked out from df_movies  \n",
    "2. Then, the KNN model is given data[idx], in other words that same index from the data matrix  \n",
    "\n",
    "This is where the issue lies. The sparse matrix is created from df_ratings, which only has movieIds movies that have a rating. If a movie does not have a single rating, it does not exist in the ratings dataframe, and so there is an index mismatch. This is seen in the full dataset at index 8403. This is also why the error happens earlier and more frequently in the small dataset, as there are a lot of ratings removed, and thus more movies that do not appear in the ratings dataset.\n",
    "\n",
    "As an example, if the title of a movieId 817 was searched for, idx would get the value 816 (index of that movie in df_movies), then index 816 from the matrix would be selected to go into the KNN model, but since movieId 817 has no ratings, this index actually points to movieId 818, and so it makes prediction on an entirely different movie than the one that was input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Solution?\n",
    "\n",
    "There are 2 easily available solutions to the issue:  \n",
    "\n",
    "1. Add in all movieIds from df_movies to the matrix when it is created  \n",
    "2. Remove all modieIds that do not have a rating from df_movies  \n",
    "\n",
    "Both of these solutions would make both dataframes contain the same unique set of movieIds, and when the matrix is created it will all line up properly regardless of search  \n",
    "\n",
    "Below, I'm solving the issue using the first solution by adding the following code to the categorical before creating the matrix:\n",
    "```py\n",
    "categories = df_movies[\"movieId\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv(\"assets/movies_small.csv\", usecols = [\"movieId\", \"title\"])\n",
    "df_ratings = pd.read_csv(\"assets/ratings_small.csv\", usecols = [\"userId\", \"movieId\", \"rating\"])\n",
    "\n",
    "movies_cat = pd.Categorical(df_ratings[\"movieId\"], categories = df_movies[\"movieId\"]) # <- here\n",
    "users_cat = pd.Categorical(df_ratings[\"userId\"])\n",
    "\n",
    "mat_movies_users = csr_matrix((df_ratings['rating'], (movies_cat.codes, users_cat.codes)))\n",
    "\n",
    "model_KNN = NearestNeighbors(metric = \"cosine\", algorithm = \"brute\")\n",
    "model_KNN.fit(mat_movies_users) # fitting model to sparse matrix\n",
    "\n",
    "def recommender(movie_name, model = model_KNN, data = mat_movies_users, n_recommendations = 9):\n",
    "    idx = process.extractOne(movie_name, df_movies[\"title\"])[2]\n",
    "\n",
    "    distances, indices = model.kneighbors(data[idx], n_neighbors = n_recommendations + 1)\n",
    "\n",
    "    indices = indices.flatten()[1:]\n",
    "    \n",
    "    # print results:\n",
    "    print(f\"Movie Selected: \\\"{df_movies.loc[idx]['title']}\\\"\\n\") # selected movie title\n",
    "    for a, i in enumerate(indices): # looping through indices:\n",
    "        print(f\"{a + 1}. {df_movies.loc[i]['title']}\") # print each title in order from closest to farthest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, everything lines up, and the predictions are much better, even on the small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Selected: \"Star Wars: Episode IV - A New Hope (1977)\"\n",
      "\n",
      "1. Star Wars: Episode V - The Empire Strikes Back (1980)\n",
      "2. Star Wars: Episode VI - Return of the Jedi (1983)\n",
      "3. Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\n",
      "4. Matrix, The (1999)\n",
      "5. Indiana Jones and the Last Crusade (1989)\n",
      "6. Back to the Future (1985)\n",
      "7. Star Wars: Episode I - The Phantom Menace (1999)\n",
      "8. Terminator, The (1984)\n",
      "9. Godfather, The (1972)\n"
     ]
    }
   ],
   "source": [
    "recommender(\"Star Wars\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the test function again, there are no longer any index mismatches found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(indices):\n",
    "    errors = 0\n",
    "    \n",
    "    for idx in indices:\n",
    "        id = df_movies.loc[idx][\"movieId\"]\n",
    "        sum_dataframe = df_ratings[df_ratings[\"movieId\"] == id][\"rating\"].sum()\n",
    "        sum_matrix = mat_movies_users[idx].sum()\n",
    "\n",
    "\n",
    "        if sum_dataframe != sum_matrix:\n",
    "            errors += 1\n",
    "            print(f\"Comparing index {idx}, result: {sum_dataframe == sum_matrix} ({sum_dataframe, sum_matrix})\")\n",
    "        \n",
    "    if errors == 0:\n",
    "        print(\"All indices tested with no mismatches\")\n",
    "    print(f\"{errors} errors found\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over every single index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All indices tested with no mismatches\n",
      "0 errors found\n"
     ]
    }
   ],
   "source": [
    "indices = [i for i in range(0, len(df_movies))]\n",
    "test(indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie_recommender-a-L8eSvj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
