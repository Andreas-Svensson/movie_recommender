{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning of Ratings Dataset\n",
    "\n",
    "### Removing less relevant data to reduce size of dataset\n",
    "\n",
    "# Important Note:\n",
    "\n",
    "Due to a workaround using categoricals in the movie recommender system, the downsized dataset created here is never used as the full dataset can be used and turned into a sparse matrix in less than one second. As this dataset does not contain incorrect readings per-se, the full dataset with all ratings seems to produce better results than the cleaned data.  \n",
    "\n",
    "One important consideration in a real world application scenario regardless of dataset size would be to remove bot ratings as they could steer recommendations towards certain movies and turn it into an unfair market where paying for bot ratings would generate more movie revenue. An example of preventing this is described below, where users with an exceedingly large amount of ratings can be discarded. Another consideration could be to detect patterns in user activity such as rating a large amount of movies in a very short time span, rating movies with an even time interval, only rating movies from specific producers or franchises, or only having 5-star ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1256677221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>481</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1256677456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1091</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1256677471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1257</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1256677460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1449</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1256677264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1      307     3.5  1256677221\n",
       "1       1      481     3.5  1256677456\n",
       "2       1     1091     1.5  1256677471\n",
       "3       1     1257     4.5  1256677460\n",
       "4       1     1449     4.5  1256677264"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings = pd.read_csv(\"assets/ratings.csv\")\n",
    "\n",
    "df_ratings.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Cleaning Data\n",
    "\n",
    "### Functions for removing cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_users(df, min_ratings, max_ratings):\n",
    "    \"\"\"\n",
    "    Drop users with more or less (or equal) ratings than respective threshold\n",
    "    \"\"\"\n",
    "    counts = df['userId'].value_counts()\n",
    "\n",
    "    # filter out users with less than min_ratings (less relevant due to not having many movie recommendations)\n",
    "    df_filtered = df[df[\"userId\"].isin(counts[counts >= min_ratings].index)]\n",
    "\n",
    "    # filter out users with more than max_ratings (outlier data)\n",
    "    # (also less relevant due to having too many movie recommendations, and high likelihood of spam bots)\n",
    "    df_filtered = df_filtered[df_filtered[\"userId\"].isin(counts[counts <= max_ratings].index)]\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_movies(df, min_ratings):\n",
    "    \"\"\"\n",
    "    Drop movies with less total ratings than threshold\n",
    "    \"\"\"\n",
    "    counts = df['movieId'].value_counts()\n",
    "\n",
    "    \n",
    "    df_filtered = df[df[\"movieId\"].isin(counts[counts >= min_ratings].index)]\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_low_average(df, min_average):\n",
    "    \"\"\"\n",
    "    Drop users with less average rating than threshold\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the mean rating for each user\n",
    "    user_mean_ratings = df.groupby('userId')['rating'].mean()\n",
    "\n",
    "    # Get the userIds with mean rating above N\n",
    "    user_ids_to_keep = user_mean_ratings[user_mean_ratings >= min_average].index\n",
    "\n",
    "    # Filter the DataFrame to keep only the desired userIds\n",
    "    df_filtered = df[df['userId'].isin(user_ids_to_keep)]\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_ratings(df, min_rating):\n",
    "    \"\"\"\n",
    "    Drop ratings below threshold\n",
    "    \"\"\"\n",
    "\n",
    "    # removing scores of less than min_rating (not relevant to recommend to anyone)\n",
    "    df_filtered = df.loc[df['rating'] >= min_rating]\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using functions to remove data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the timestamp column as it is never used in the recommendation system\n",
    "df_filtered = df_ratings.drop(columns = \"timestamp\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out users with less than n ratings  \n",
    "Reasoning: likely does not add much to overall performance  \n",
    "\n",
    "Filtering out users with more than N ratings  \n",
    "Reasoning: likely a lot of bots with this amount of rating  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = drop_users(df_filtered, 2, 2000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out movies with less than N ratings  \n",
    "Reasoning: extremely niche movies, mostly old movies that nobody ever watches, will reduce size of matrix without losing valuable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = drop_movies(df_filtered, 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out users with average rating below N  \n",
    "Reasoning: mostly low ratings do not add much to recommendations, likely removes a lot of trolls with low ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = drop_low_average(df_filtered, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out ratings below N  \n",
    "Reasoning: high ratings are more relevant for giving accurate suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = drop_ratings(df_filtered, 3.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Data Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset reduced from 27,753,444 to 16,626,813 (a reduction of 11,126,631 rows or 40.09%)\n",
      "\n",
      "Amount users reduced from 283,228 to 273,120 (a reduction of 10,108 users or 3.57%)\n",
      "\n",
      "Amount movies reduced from 53,889 to 25,674 (a reduction of 28,215 movies or 52.36%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "original = len(df_ratings) # length of dataset pre-filter\n",
    "new = len(df_filtered) # length of dataset post-filter\n",
    "\n",
    "# printing change in length of dataset\n",
    "print(f\"Length of dataset reduced from {original:,} to {new:,} (a reduction of {original - new:,} rows or {(original - new) / original * 100:.2f}%)\\n\")\n",
    "\n",
    "original = len(df_ratings[\"userId\"].unique()) # amt users in dataset pre-filter\n",
    "new = len(df_filtered[\"userId\"].unique()) # amt users in dataset post-filter\n",
    "\n",
    "# print changes in amt users\n",
    "print(f\"Amount users reduced from {original:,} to {new:,} (a reduction of {original - new:,} users or {(original - new) / original * 100:.2f}%)\\n\")\n",
    "\n",
    "original = len(df_ratings[\"movieId\"].unique()) # amt movies in dataset pre-filter\n",
    "new = len(df_filtered[\"movieId\"].unique()) # amt movies in dataset post-filter\n",
    "\n",
    "# print changes in amt movies\n",
    "print(f\"Amount movies reduced from {original:,} to {new:,} (a reduction of {original - new:,} movies or {(original - new) / original * 100:.2f}%)\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Cleaned Data\n",
    "Store as .csv and import in other files if they need to run a smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv(\"assets/ratings_clean.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie_recommender-a-L8eSvj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
